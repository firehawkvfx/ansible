# configures autologin for open vpn and routes.

# to update routes only for the vagrant host, execute 
# ansible-playbook -i ansible/inventory ansible/openvpn.yaml -v --extra-vars "" --tags add-routes

- hosts: ansible_control
  remote_user: vagrant
  gather_facts: "{{ variable_gather_facts | default('true') }}"
  become: true

  tasks:
    - name: Test local connection.
      debug:
        msg: "test local connection"

- hosts: "{{ variable_host | default('openvpnip') }}"
  remote_user: openvpnas
  gather_facts: "{{ variable_gather_facts | default('true') }}"
  become: true

  tasks:
    - name: Test vpn connection.
      debug:
        msg: "test vpn connection"

- hosts: "{{ variable_host | default('openvpnip') }}"
  remote_user: openvpnas
  become: true

  vars:
    client_network: None
    client_netmask_bits: None
    
  pre_tasks:
    - name: create dir.
      file:
        path: /usr/local/openvpn_as/scripts/seperate
        state: directory

    - name: configure openvpn server settings
      shell: |
        /usr/local/openvpn_as/scripts/sacli -k vpn.daemon.0.client.network -v {{ client_network }} ConfigPut
        /usr/local/openvpn_as/scripts/sacli -k vpn.daemon.0.client.netmask_bits -v {{ client_netmask_bits }} ConfigPut
        /usr/local/openvpn_as/scripts/sacli --key 'vpn.server.tls_auth' --value 'true' ConfigPut
        /usr/local/openvpn_as/scripts/sacli --key vpn.server.routing.gateway_access --value 'true' ConfigPut
        /usr/local/openvpn_as/scripts/sacli --key vpn.server.routing.private_network.0 --value '{{ private_subnet1 }}' ConfigPut
        /usr/local/openvpn_as/scripts/sacli --key vpn.server.routing.private_network.1 --value '{{ public_subnet1 }}' ConfigPut
        /usr/local/openvpn_as/scripts/sacli --key vpn.server.routing.private_network.2 --value '{{ client_network }}/{{ client_netmask_bits }}' ConfigPut
        /usr/local/openvpn_as/scripts/sacli --key vpn.server.routing.private_access --value 'route' ConfigPut
        /usr/local/openvpn_as/scripts/sacli --key 'vpn.client.routing.reroute_dns' --value 'true' ConfigPut
        /usr/local/openvpn_as/scripts/sacli --key 'vpn.server.dhcp_option.domain' --value 'ap-southeast-2.compute.internal' ConfigPut
        /usr/local/openvpn_as/scripts/sacli --key 'vpn.server.routing.allow_private_nets_to_clients' --value 'true' ConfigPut
        /usr/local/openvpn_as/scripts/sacli start
        cd /usr/local/openvpn_as/scripts/
        ./sacli --user {{ openvpn_user }} --key 'prop_autologin' --value 'true' UserPropPut
        ./sacli --user {{ openvpn_user }} --key 'c2s_route.0' --value '{{ remote_subnet_cidr }}' UserPropPut
        ./sacli --user {{ openvpn_user }} AutoGenerateOnBehalfOf
        ./sacli -o ./seperate --cn {{ openvpn_user }} get5
        chown {{ openvpn_user }} seperate/*
        /usr/local/openvpn_as/scripts/sacli start
        ls -la seperate

  roles:
    - role: openvpn


- hosts: ansible_control
  remote_user: vagrant
  gather_facts: "{{ variable_gather_facts | default('true') }}"
  become: true

  tasks:
    - name: test update -
      debug:
        msg: "updating autologin. {{ softnas1_private_ip1 }}"

    - name: Ansible copy local openvpn files to /etc/openvpn
      copy:
        src: ~/openvpn_config/{{ item }}
        dest: /etc/openvpn/{{ item }}
        owner: vagrant
        group: vagrant
        mode: 0400
        force: yes
      with_items:
        - openvpn.conf
        - ca.crt
        - client.crt
        - client.key
        - ta.key
        - yourserver.txt
      become: yes

    - name: Ansible allow autostart, uncomment
      replace:
        path: /etc/default/openvpn
        regexp: '^#(.*AUTOSTART="all".*)'
        replace: '\1'
      become: yes

    - name: allow ip forwarding, uncomment
      replace:
        path: /etc/sysctl.conf
        regexp: '^#(.*net.ipv4.ip_forward=1.*)'
        replace: '\1'
      become: yes      

    - name: force systemd to reread configs (2.4 and above)
      systemd:
        daemon_reload: yes
        name: openvpn
        state: started
        enabled: yes
      become: yes

    - name: wait for first restart for service.
      command: sleep 30

    - name: force systemd to reread configs (2.4 and above)
      systemd:
        daemon_reload: yes
        name: openvpn
        state: restarted
        enabled: yes
      become: yes

    - name: configure routes to opposite dev/prod environment so that nodes in both envs can access licence server
      shell: |
        ip route del {{ item.subnet }}
        ip route add {{ item.subnet }} via {{ item.next_hop }} dev {{ vpn_nic }}
      with_items:
        - { subnet: "{{ private_subnet1_prod }}", next_hop: "{{ openfirehawkserver_prod }}" }
        - { subnet: "{{ public_subnet1_prod }}", next_hop: "{{ openfirehawkserver_prod }}" }
        - { subnet: "{{ vpn_cidr_prod }}", next_hop: "{{ openfirehawkserver_prod }}" }
      when: envtier == 'dev'
      become: yes
      tags:
        - add-routes

    - name: insert/update block in /etc/network/interfaces for routes. configure routes to opposite dev/prod environment so that nodes in both envs can access licence server.  Remove route if it exists and re apply it.
      blockinfile:
        path: /etc/network/interfaces
        block: |
          up route add -net {{ item.subnet }} gw {{ item.next_hop }}
        marker: "# {mark} ANSIBLE MANAGED BLOCK {{ item.subnet }}"
      with_items:
        - { subnet: "{{ private_subnet1_prod }}", next_hop: "{{ openfirehawkserver_prod }}" }
        - { subnet: "{{ public_subnet1_prod }}", next_hop: "{{ openfirehawkserver_prod }}" }
        - { subnet: "{{ vpn_cidr_prod }}", next_hop: "{{ openfirehawkserver_prod }}" }
      when: envtier == 'dev'
      become: yes
      tags:
        - add-routes

    - name: configure routes to opposite dev/prod environment so that nodes in both envs can access licence server.  Remove route if it exists and re apply it.
      shell: |
        ip route del {{ item.subnet }}
        ip route add {{ item.subnet }} via {{ item.next_hop }} dev {{ vpn_nic }}
      with_items:
        - { subnet: "{{ private_subnet1_dev }}", next_hop: "{{ openfirehawkserver_dev }}" }
        - { subnet: "{{ public_subnet1_dev }}", next_hop: "{{ openfirehawkserver_dev }}" }
        - { subnet: "{{ vpn_cidr_dev }}", next_hop: "{{ openfirehawkserver_dev }}" }
      when: envtier == 'prod'
      become: yes
      tags:
        - add-routes

    - name: insert/update block in /etc/network/interfaces for routes.  configure routes to opposite dev/prod environment so that nodes in both envs can access licence server.  Remove route if it exists and re apply it.
      blockinfile:
        path: /etc/network/interfaces
        block: |
          up route add -net {{ item.subnet }} gw {{ item.next_hop }}
        marker: "# {mark} ANSIBLE MANAGED BLOCK {{ item.subnet }}"
      with_items:
        - { subnet: "{{ private_subnet1_dev }}", next_hop: "{{ openfirehawkserver_dev }}" }
        - { subnet: "{{ public_subnet1_dev }}", next_hop: "{{ openfirehawkserver_dev }}" }
        - { subnet: "{{ vpn_cidr_dev }}", next_hop: "{{ openfirehawkserver_dev }}" }
      when: envtier == 'prod'
      become: yes
      tags:
        - add-routes